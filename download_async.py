import aiohttp
import asyncio
import os
import signal
import sys
import time
import psutil
import gc
from throttler import throttle

class AsyncTrafficFlowManager:
    def __init__(self, max_memory_mb=100, chunk_size=8192):
        self.running = True
        self.downloaded_bytes = 0
        self.start_time = time.time()
        self.max_memory_mb = max_memory_mb
        self.chunk_size = chunk_size
        self.active_downloads = 0
        self.max_active_downloads = 5  # å¼‚æ­¥ç‰ˆæœ¬å¯ä»¥æ”¯æŒæ›´é«˜å¹¶å‘
        
        # æ ¹æ®å†…å­˜é™åˆ¶è°ƒæ•´å¹¶å‘æ•°
        self.adjust_concurrency_based_on_memory()
        
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
    
    def adjust_concurrency_based_on_memory(self):
        """æ ¹æ®å¯ç”¨å†…å­˜è°ƒæ•´å¹¶å‘æ•°"""
        try:
            available_memory = psutil.virtual_memory().available / (1024 * 1024)
            safe_concurrency = max(1, min(20, int(available_memory * 0.1 / 10)))
            self.max_active_downloads = min(self.max_active_downloads, safe_concurrency)
            print(f"å¯ç”¨å†…å­˜: {available_memory:.1f} MB, è®¾ç½®æœ€å¤§å¹¶å‘æ•°: {self.max_active_downloads}")
        except Exception as e:
            print(f"å†…å­˜æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å¹¶å‘æ•°: {e}")
    
    def signal_handler(self, signum, frame):
        print(f"\næ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨åœæ­¢ç¨‹åº...")
        self.running = False
    
    def get_memory_usage(self):
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡"""
        try:
            process = psutil.Process(os.getpid())
            return process.memory_info().rss / (1024 * 1024)
        except:
            return 0
    
    def is_memory_safe(self):
        """æ£€æŸ¥å†…å­˜æ˜¯å¦å®‰å…¨"""
        memory_usage = self.get_memory_usage()
        return memory_usage < self.max_memory_mb
    
    async def wait_for_memory_safe(self, timeout=30):
        """ç­‰å¾…å†…å­˜ä½¿ç”¨é™åˆ°å®‰å…¨æ°´å¹³"""
        start_time = time.time()
        while self.running and time.time() - start_time < timeout:
            if self.is_memory_safe():
                return True
            print(f"å†…å­˜ä½¿ç”¨è¿‡é«˜ ({self.get_memory_usage():.1f} MB)ï¼Œç­‰å¾…é‡Šæ”¾...")
            await asyncio.sleep(1)
        return self.is_memory_safe()
    
    def load_urls_from_file(self, filename='urls.txt'):
        """ä»æ–‡ä»¶åŠ è½½URLåˆ—è¡¨"""
        urls = []
        if os.path.exists(filename):
            with open(filename, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        urls.append(line)
            print(f"ä» {filename} åŠ è½½äº† {len(urls)} ä¸ªURL")
        else:
            urls = [
                "https://httpbin.org/bytes/102400",
                "https://httpbin.org/bytes/1048576",
                "https://httpbin.org/bytes/5242880",
            ]
            print(f"ä½¿ç”¨é»˜è®¤æµ‹è¯•URL ({len(urls)} ä¸ª)")
        return urls

    async def async_download_and_discard(self, session, url, timeout=30, max_speed_kbps=0):
        """å¼‚æ­¥ä¸‹è½½æ–‡ä»¶å¹¶ä¸¢å¼ƒï¼Œæ”¯æŒé™é€Ÿ"""
        if not self.running:
            return False
            
        # æ£€æŸ¥å†…å­˜å®‰å…¨
        if not self.is_memory_safe():
            print(f"âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œè·³è¿‡ä¸‹è½½: {url}")
            return False
        
        # å¹¶å‘æ§åˆ¶
        self.active_downloads += 1
        
        try:
            async with session.get(url, timeout=timeout) as response:
                response.raise_for_status()
                
                total_size = 0
                chunk_count = 0
                
                if max_speed_kbps > 0:
                    # è®¡ç®—é™é€Ÿå‚æ•°
                    bytes_per_second = max_speed_kbps * 1024
                    chunk_size = min(self.chunk_size, 4096)
                    calls_per_second = bytes_per_second / chunk_size
                    
                    @throttle(rate=calls_per_second if calls_per_second > 0 else 1)
                    async def process_chunk(chunk):
                        nonlocal total_size, chunk_count
                        if not self.running:
                            return False
                        
                        chunk_size = len(chunk)
                        total_size += chunk_size
                        self.downloaded_bytes += chunk_size
                        chunk_count += 1
                        
                        # å®šæœŸåƒåœ¾å›æ”¶
                        if chunk_count % 100 == 0:
                            gc.collect()
                        
                        # ç«‹å³ä¸¢å¼ƒchunk
                        del chunk
                        return True
                
                    async for chunk in response.content.iter_chunked(chunk_size):
                        if not self.running:
                            return False
                        await process_chunk(chunk)
                else:
                    # æ— é€Ÿåº¦é™åˆ¶
                    async for chunk in response.content.iter_chunked(min(self.chunk_size, 4096)):
                        if not self.running:
                            return False
                        
                        chunk_size = len(chunk)
                        total_size += chunk_size
                        self.downloaded_bytes += chunk_size
                        chunk_count += 1
                        
                        # å®šæœŸåƒåœ¾å›æ”¶
                        if chunk_count % 100 == 0:
                            gc.collect()
                        
                        # ç«‹å³ä¸¢å¼ƒchunk
                        del chunk
                
                # æœ€ç»ˆåƒåœ¾å›æ”¶
                gc.collect()
                
                speed_info = ""
                if max_speed_kbps > 0:
                    speed_info = f" (é™é€Ÿ: {max_speed_kbps} KB/s)"
                    
                memory_info = f" [å†…å­˜: {self.get_memory_usage():.1f} MB]"
                print(f"âœ“ æˆåŠŸä¸‹è½½å¹¶ä¸¢å¼ƒ: {url} (å¤§å°: {total_size} å­—èŠ‚, åˆ†å—: {chunk_count}){speed_info}{memory_info}")
                return True
                
        except Exception as e:
            print(f"âœ— ä¸‹è½½å¤±è´¥ {url}: {e}")
            return False
        finally:
            self.active_downloads -= 1

    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        elapsed_time = time.time() - self.start_time
        total_mb = self.downloaded_bytes / (1024 * 1024)
        avg_speed = total_mb / elapsed_time if elapsed_time > 0 else 0
        memory_usage = self.get_memory_usage()
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   è¿è¡Œæ—¶é—´: {elapsed_time:.1f} ç§’")
        print(f"   æ€»ä¸‹è½½é‡: {total_mb:.2f} MB")
        print(f"   å¹³å‡é€Ÿåº¦: {avg_speed:.2f} MB/s")
        print(f"   å†…å­˜ä½¿ç”¨: {memory_usage:.1f} MB / {self.max_memory_mb} MB")
        print(f"   æ´»è·ƒä¸‹è½½: {self.active_downloads}/{self.max_active_downloads}")

    async def async_batch_download(self, urls, interval=1, repeat_count=None, 
                                 max_speed_kbps=0, per_download_speed_kbps=0):
        """å¼‚æ­¥æ‰¹é‡ä¸‹è½½ï¼Œæ”¯æŒé™é€Ÿ"""
        count = 0
        
        # é‡ç½®ç»Ÿè®¡
        self.downloaded_bytes = 0
        self.start_time = time.time()
        
        # è®¾ç½®è¶…æ—¶
        timeout = aiohttp.ClientTimeout(total=30)
        
        async with aiohttp.ClientSession(timeout=timeout) as session:
            while self.running and (repeat_count is None or count < repeat_count):
                count += 1
                print(f"\n--- ç¬¬ {count} è½®ä¸‹è½½å¼€å§‹ ---")
                print(f"å¼‚æ­¥å¹¶å‘ä¸‹è½½: {self.max_active_downloads} æœ€å¤§å¹¶å‘")
                
                if max_speed_kbps > 0:
                    print(f"å…¨å±€é™é€Ÿ: {max_speed_kbps} KB/s")
                if per_download_speed_kbps > 0:
                    print(f"å•æ–‡ä»¶é™é€Ÿ: {per_download_speed_kbps} KB/s")
                
                # æ£€æŸ¥å†…å­˜çŠ¶æ€
                if not self.is_memory_safe():
                    print("âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œç­‰å¾…é‡Šæ”¾...")
                    if not await self.wait_for_memory_safe():
                        print("âŒ å†…å­˜é‡Šæ”¾è¶…æ—¶ï¼Œè·³è¿‡æœ¬è½®ä¸‹è½½")
                        continue
                
                # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘
                semaphore = asyncio.Semaphore(self.max_active_downloads)
                
                async def download_with_semaphore(url):
                    async with semaphore:
                        return await self.async_download_and_discard(
                            session, url, 
                            max_speed_kbps=per_download_speed_kbps
                        )
                
                # åˆ›å»ºæ‰€æœ‰ä¸‹è½½ä»»åŠ¡
                tasks = [download_with_semaphore(url) for url in urls]
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # ç»Ÿè®¡ç»“æœ
                success_count = sum(1 for r in results if r is True)
                print(f"æœ¬è½®å®Œæˆ: {success_count}/{len(urls)} ä¸ªæ–‡ä»¶")
                
                # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
                self.print_statistics()
                
                if (self.running and 
                    (repeat_count is None or count < repeat_count)):
                    print(f"ç­‰å¾… {interval} ç§’åå¼€å§‹ä¸‹ä¸€è½®...")
                    
                    # åœ¨ç­‰å¾…æœŸé—´å¼ºåˆ¶åƒåœ¾å›æ”¶
                    gc.collect()
                    
                    # åˆ†æ®µç­‰å¾…ä»¥ä¾¿å“åº”åœæ­¢ä¿¡å·
                    for i in range(interval):
                        if not self.running:
                            break
                        # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡å†…å­˜
                        if i % 5 == 0:
                            memory_usage = self.get_memory_usage()
                            if memory_usage > self.max_memory_mb * 0.8:
                                print(f"âš ï¸ å†…å­˜ä½¿ç”¨è¾ƒé«˜: {memory_usage:.1f} MBï¼Œæå‰åƒåœ¾å›æ”¶")
                                gc.collect()
                        await asyncio.sleep(1)

async def main_async():
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    max_memory_mb = int(os.getenv('MAX_MEMORY_MB', '100'))
    chunk_size = int(os.getenv('CHUNK_SIZE', '8192'))
    
    manager = AsyncTrafficFlowManager(
        max_memory_mb=max_memory_mb,
        chunk_size=chunk_size
    )
    
    interval = int(os.getenv('DOWNLOAD_INTERVAL', '1'))
    repeat_count = os.getenv('REPEAT_COUNT')
    repeat_count = int(repeat_count) if repeat_count else None
    max_speed_kbps = int(os.getenv('MAX_SPEED_KBPS', '0'))
    per_download_speed_kbps = int(os.getenv('PER_DOWNLOAD_SPEED_KBPS', '0'))
    
    # åŠ è½½URLåˆ—è¡¨
    urls = manager.load_urls_from_file('/app/urls.txt')
    
    print("=" * 60)
    print("ğŸš€ TrafficFlow - å¼‚æ­¥ç½‘ç»œæµé‡æµ‹è¯•å·¥å…·")
    print("=" * 60)
    print(f"ç›‘æ§ URL æ•°é‡: {len(urls)}")
    print(f"ä¸‹è½½é—´éš”: {interval} ç§’")
    print(f"æœ€å¤§å¹¶å‘ä¸‹è½½: {manager.max_active_downloads}")
    print(f"å†…å­˜é™åˆ¶: {max_memory_mb} MB")
    print(f"å—å¤§å°: {chunk_size} å­—èŠ‚")
    print(f"é‡å¤æ¬¡æ•°: {'æ— é™' if repeat_count is None else repeat_count}")
    if max_speed_kbps > 0:
        print(f"å…¨å±€é™é€Ÿ: {max_speed_kbps} KB/s")
    if per_download_speed_kbps > 0:
        print(f"å•æ–‡ä»¶é™é€Ÿ: {per_download_speed_kbps} KB/s")
    print("=" * 60)
    print("æŒ‰ Ctrl+C åœæ­¢ç¨‹åº")
    
    try:
        await manager.async_batch_download(
            urls=urls,
            interval=interval,
            repeat_count=repeat_count,
            max_speed_kbps=max_speed_kbps,
            per_download_speed_kbps=per_download_speed_kbps
        )
    except Exception as e:
        print(f"ç¨‹åºå¼‚å¸¸: {e}")
    finally:
        print("\n" + "=" * 60)
        print("æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯:")
        manager.print_statistics()
        print("TrafficFlow å¼‚æ­¥ç‰ˆæœ¬å·²åœæ­¢")

if __name__ == "__main__":
    asyncio.run(main_async())