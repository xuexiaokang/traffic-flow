import requests
import time
import threading
from concurrent.futures import ThreadPoolExecutor
import sys
import os
import signal
import math
import psutil
import gc

class TrafficFlowManager:
    def __init__(self, max_memory_mb=100, chunk_size=8192):
        self.running = True
        self.downloaded_bytes = 0
        self.start_time = time.time()
        self.max_memory_mb = max_memory_mb
        self.chunk_size = chunk_size
        self.active_downloads = 0
        self.max_active_downloads = 3
        
        # æ ¹æ®å†…å­˜é™åˆ¶è°ƒæ•´å¹¶å‘æ•°
        self.adjust_concurrency_based_on_memory()
        
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
    
    def adjust_concurrency_based_on_memory(self):
        """æ ¹æ®å¯ç”¨å†…å­˜è°ƒæ•´å¹¶å‘æ•°"""
        try:
            available_memory = psutil.virtual_memory().available / (1024 * 1024)
            safe_concurrency = max(1, min(10, int(available_memory * 0.1 / 10)))
            self.max_active_downloads = min(self.max_active_downloads, safe_concurrency)
            print(f"å¯ç”¨å†…å­˜: {available_memory:.1f} MB, è®¾ç½®æœ€å¤§å¹¶å‘æ•°: {self.max_active_downloads}")
        except Exception as e:
            print(f"å†…å­˜æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å¹¶å‘æ•°: {e}")
    
    def signal_handler(self, signum, frame):
        print(f"\næ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨åœæ­¢ç¨‹åº...")
        self.running = False
    
    def get_memory_usage(self):
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡"""
        try:
            process = psutil.Process(os.getpid())
            return process.memory_info().rss / (1024 * 1024)
        except:
            return 0
    
    def is_memory_safe(self):
        """æ£€æŸ¥å†…å­˜æ˜¯å¦å®‰å…¨"""
        memory_usage = self.get_memory_usage()
        return memory_usage < self.max_memory_mb
    
    def wait_for_memory_safe(self, timeout=30):
        """ç­‰å¾…å†…å­˜ä½¿ç”¨é™åˆ°å®‰å…¨æ°´å¹³"""
        start_time = time.time()
        while self.running and time.time() - start_time < timeout:
            if self.is_memory_safe():
                return True
            print(f"å†…å­˜ä½¿ç”¨è¿‡é«˜ ({self.get_memory_usage():.1f} MB)ï¼Œç­‰å¾…é‡Šæ”¾...")
            time.sleep(1)
        return self.is_memory_safe()
    
    def load_urls_from_file(self, filename='urls.txt'):
        """ä»æ–‡ä»¶åŠ è½½URLåˆ—è¡¨"""
        urls = []
        if os.path.exists(filename):
            with open(filename, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        urls.append(line)
            print(f"ä» {filename} åŠ è½½äº† {len(urls)} ä¸ªURL")
        else:
            urls = [
                "https://httpbin.org/bytes/102400",
                "https://httpbin.org/bytes/1048576",
                "https://httpbin.org/bytes/5242880",
            ]
            print(f"ä½¿ç”¨é»˜è®¤æµ‹è¯•URL ({len(urls)} ä¸ª)")
        
        return urls

    def limit_download_speed(self, chunk, max_speed_kbps):
        """é™åˆ¶ä¸‹è½½é€Ÿåº¦"""
        if max_speed_kbps <= 0:
            return
            
        chunk_size = len(chunk)
        expected_time = chunk_size / (max_speed_kbps * 1024 / 8)
        
        actual_time = time.time() - getattr(self, '_last_chunk_time', time.time())
        if actual_time < expected_time:
            sleep_time = expected_time - actual_time
            time.sleep(sleep_time)
        
        self._last_chunk_time = time.time()

    def download_and_discard(self, url, timeout=30, max_speed_kbps=0):
        """ä¸‹è½½æ–‡ä»¶å¹¶ç›´æ¥ä¸¢å¼ƒå†…å®¹"""
        if not self.running:
            return False
        
        if not self.is_memory_safe():
            print(f"âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œè·³è¿‡ä¸‹è½½: {url}")
            return False
        
        with threading.Lock():
            if self.active_downloads >= self.max_active_downloads:
                print(f"âš ï¸ å¹¶å‘æ•°å·²è¾¾ä¸Šé™({self.max_active_downloads})ï¼Œç­‰å¾…ä¸‹è½½æ§½ä½...")
                time.sleep(1)
                return self.download_and_discard(url, timeout, max_speed_kbps)
            
            self.active_downloads += 1
        
        try:
            chunk_size = min(self.chunk_size, 4096)
            
            response = requests.get(url, timeout=timeout, stream=True)
            response.raise_for_status()
            
            total_size = 0
            chunk_count = 0
            
            for chunk in response.iter_content(chunk_size=chunk_size):
                if not self.running:
                    return False
                
                total_size += len(chunk)
                self.downloaded_bytes += len(chunk)
                chunk_count += 1
                
                if chunk_count % 100 == 0:
                    gc.collect()
                
                if max_speed_kbps > 0:
                    self.limit_download_speed(chunk, max_speed_kbps)
                
                del chunk
            
            gc.collect()
            
            speed_info = ""
            if max_speed_kbps > 0:
                speed_info = f" (é™é€Ÿ: {max_speed_kbps} KB/s)"
                
            memory_info = f" [å†…å­˜: {self.get_memory_usage():.1f} MB]"
            print(f"âœ“ æˆåŠŸä¸‹è½½å¹¶ä¸¢å¼ƒ: {url} (å¤§å°: {total_size} å­—èŠ‚, åˆ†å—: {chunk_count}){speed_info}{memory_info}")
            return True
            
        except requests.exceptions.RequestException as e:
            print(f"âœ— ä¸‹è½½å¤±è´¥ {url}: {e}")
            return False
        finally:
            self.active_downloads -= 1
            if 'response' in locals():
                response.close()

    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        elapsed_time = time.time() - self.start_time
        total_mb = self.downloaded_bytes / (1024 * 1024)
        avg_speed = total_mb / elapsed_time if elapsed_time > 0 else 0
        memory_usage = self.get_memory_usage()
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   è¿è¡Œæ—¶é—´: {elapsed_time:.1f} ç§’")
        print(f"   æ€»ä¸‹è½½é‡: {total_mb:.2f} MB")
        print(f"   å¹³å‡é€Ÿåº¦: {avg_speed:.2f} MB/s")
        print(f"   å†…å­˜ä½¿ç”¨: {memory_usage:.1f} MB / {self.max_memory_mb} MB")
        print(f"   æ´»è·ƒä¸‹è½½: {self.active_downloads}/{self.max_active_downloads}")

    def batch_download(self, urls, interval=1, max_workers=5, repeat_count=None, 
                      max_speed_kbps=0, per_download_speed_kbps=0):
        """æ‰¹é‡ä¸‹è½½æ–‡ä»¶"""
        count = 0
        
        max_workers = min(max_workers, self.max_active_downloads)
        
        self.downloaded_bytes = 0
        self.start_time = time.time()
        
        while self.running and (repeat_count is None or count < repeat_count):
            count += 1
            print(f"\n--- ç¬¬ {count} è½®ä¸‹è½½å¼€å§‹ ---")
            print(f"å¹¶å‘è®¾ç½®: {max_workers} å·¥ä½œçº¿ç¨‹, {self.max_active_downloads} æœ€å¤§å¹¶å‘ä¸‹è½½")
            
            if max_speed_kbps > 0:
                print(f"å…¨å±€é™é€Ÿ: {max_speed_kbps} KB/s")
            if per_download_speed_kbps > 0:
                print(f"å•æ–‡ä»¶é™é€Ÿ: {per_download_speed_kbps} KB/s")
            
            if not self.is_memory_safe():
                print("âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œç­‰å¾…é‡Šæ”¾...")
                if not self.wait_for_memory_safe():
                    print("âŒ å†…å­˜é‡Šæ”¾è¶…æ—¶ï¼Œè·³è¿‡æœ¬è½®ä¸‹è½½")
                    continue
            
            individual_speed = 0
            if per_download_speed_kbps > 0:
                individual_speed = per_download_speed_kbps
            elif max_speed_kbps > 0 and max_workers > 0:
                individual_speed = max_speed_kbps / max_workers
            
            download_semaphore = threading.Semaphore(self.max_active_downloads)
            
            def download_with_semaphore(url):
                with download_semaphore:
                    return self.download_and_discard(url, max_speed_kbps=individual_speed)
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                results = list(executor.map(download_with_semaphore, urls))
            
            success_count = sum(1 for r in results if r)
            print(f"æœ¬è½®å®Œæˆ: {success_count}/{len(urls)} ä¸ªæ–‡ä»¶")
            
            self.print_statistics()
            
            if (self.running and 
                (repeat_count is None or count < repeat_count)):
                print(f"ç­‰å¾… {interval} ç§’åå¼€å§‹ä¸‹ä¸€è½®...")
                
                gc.collect()
                
                for i in range(interval):
                    if not self.running:
                        break
                    if i % 5 == 0:
                        memory_usage = self.get_memory_usage()
                        if memory_usage > self.max_memory_mb * 0.8:
                            print(f"âš ï¸ å†…å­˜ä½¿ç”¨è¾ƒé«˜: {memory_usage:.1f} MBï¼Œæå‰åƒåœ¾å›æ”¶")
                            gc.collect()
                    time.sleep(1)

def main():
    max_memory_mb = int(os.getenv('MAX_MEMORY_MB', '100'))
    chunk_size = int(os.getenv('CHUNK_SIZE', '8192'))
    
    manager = TrafficFlowManager(
        max_memory_mb=max_memory_mb,
        chunk_size=chunk_size
    )
    
    interval = int(os.getenv('DOWNLOAD_INTERVAL', '2'))
    max_workers = int(os.getenv('MAX_WORKERS', '3'))
    repeat_count = os.getenv('REPEAT_COUNT')
    repeat_count = int(repeat_count) if repeat_count else None
    max_speed_kbps = int(os.getenv('MAX_SPEED_KBPS', '0'))
    per_download_speed_kbps = int(os.getenv('PER_DOWNLOAD_SPEED_KBPS', '0'))
    
    urls = manager.load_urls_from_file('/app/urls.txt')
    
    print("=" * 60)
    print("ğŸš€ TrafficFlow - ç½‘ç»œæµé‡æµ‹è¯•å·¥å…·")
    print("=" * 60)
    print(f"ç›‘æ§ URL æ•°é‡: {len(urls)}")
    print(f"ä¸‹è½½é—´éš”: {interval} ç§’")
    print(f"å·¥ä½œçº¿ç¨‹: {max_workers}")
    print(f"æœ€å¤§å¹¶å‘ä¸‹è½½: {manager.max_active_downloads}")
    print(f"å†…å­˜é™åˆ¶: {max_memory_mb} MB")
    print(f"å—å¤§å°: {chunk_size} å­—èŠ‚")
    print(f"é‡å¤æ¬¡æ•°: {'æ— é™' if repeat_count is None else repeat_count}")
    if max_speed_kbps > 0:
        print(f"å…¨å±€é™é€Ÿ: {max_speed_kbps} KB/s")
    if per_download_speed_kbps > 0:
        print(f"å•æ–‡ä»¶é™é€Ÿ: {per_download_speed_kbps} KB/s")
    print("=" * 60)
    print("æŒ‰ Ctrl+C åœæ­¢ç¨‹åº")
    
    try:
        manager.batch_download(
            urls=urls,
            interval=interval,
            max_workers=max_workers,
            repeat_count=repeat_count,
            max_speed_kbps=max_speed_kbps,
            per_download_speed_kbps=per_download_speed_kbps
        )
    except Exception as e:
        print(f"ç¨‹åºå¼‚å¸¸: {e}")
    finally:
        print("\n" + "=" * 60)
        print("æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯:")
        manager.print_statistics()
        print("TrafficFlow å·²åœæ­¢")

if __name__ == "__main__":
    main()